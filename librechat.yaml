version: 1.1.4

endpoints:
  custom:
    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai"
      models:
        default: ["sonar-pro"]
        list:
          - model: "sonar-pro"
            label: "Sonar Pro"
          - model: "sonar-small"
            label: "Sonar Small"
      modelDisplayLabel: "Perplexity AI"
      titleConvo: true
      titleModel: "sonar-pro"
      summarize: false
      summaryModel: "sonar-pro"
      authorizationType: "bearer"

    - name: "HuggingFace"
      apiKey: "${HF_API_KEY}"
      # FIX 1: Changed baseURL for HuggingFace.
      # It should be the base inference API, not include the model path.
      baseURL: "https://api-inference.huggingface.co"
      models:
        # The model name should include the full path as the baseURL no longer has it.
        # This was already correct in your previous YAML.
        default: ["meta-llama/Llama-4-Maverick-17B-128E-Instruct"]
        list:
          - model: "meta-llama/Llama-4-Maverick-17B-128E-Instruct"
            label: "LLaMA 4 Maverick"
      modelDisplayLabel: "HF LLaMA 4 Maverick"
      titleConvo: false
      titleModel: "meta-llama/Llama-4-Maverick-17B-128E-Instruct"
      summarize: false
      summaryModel: "meta-llama/Llama-4-Maverick-17B-128E-Instruct"
      useChat: false
      stream: false
      authorizationType: "bearer"

  - name: "Claude-AIMM"
    apiKey: "dummy"  # Only needed if LiteLLM requires one, otherwise use "none" or leave it out
    baseURL: "https://litellm-308665817092.us-west1.run.app/v1"
    models:
      default: ["claude-haiku"]
      list:
        - model: "claude-haiku"
          label: "Claude 3.5 Haiku"
    modelDisplayLabel: "Claude 3.5 AIMM"
    titleConvo: true
    titleModel: "claude-haiku"
    summarize: false
    summaryModel: "claude-haiku"
    authorizationType: "none"
    useChat: true
    stream: true

